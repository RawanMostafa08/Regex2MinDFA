{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVdG0vBDABkI"
      },
      "source": [
        "# Postfix To NFA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "LkZDa532WJ8i"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from collections import defaultdict\n",
        "import shunting_yard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "d2-bIz7fVIcn"
      },
      "outputs": [],
      "source": [
        "epsilon = \"\\u03B5\"\n",
        "alphanumerics = 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789'\n",
        "\n",
        "class State:\n",
        "    def __init__(self,name):\n",
        "        self.name = name\n",
        "        self.out_edges = []\n",
        "        self.in_edges = []\n",
        "\n",
        "class Edge:\n",
        "    def __init__(self, label:str ,dest:State):\n",
        "        self.label = label\n",
        "        self.dest = dest\n",
        "\n",
        "class NFA:\n",
        "    def __init__(self, char: str, start: State, accepting: State):\n",
        "        self.states = [start,accepting]\n",
        "        self.start = start\n",
        "        self.accepting = accepting\n",
        "\n",
        "        # edge = Edge(char,self.accepting)\n",
        "        # self.start.out_edges.append(edge)\n",
        "        # self.accepting.in_edges.append(edge)\n",
        "\n",
        "    @staticmethod\n",
        "    def postfix2NFA(postfix:str):\n",
        "        stack = []\n",
        "        state_counter= 1\n",
        "\n",
        "        for char in postfix:\n",
        "            if char=='.':\n",
        "                nfa2 = stack.pop()\n",
        "                nfa1 = stack.pop()\n",
        "\n",
        "                edge = Edge(epsilon,nfa2.start)\n",
        "                nfa1.accepting.out_edges.append(edge)\n",
        "                nfa2.start.in_edges.append(edge)\n",
        "\n",
        "                concatenated_nfa = NFA(epsilon, nfa1.start, nfa2.accepting)\n",
        "\n",
        "                concatenated_nfa.states = nfa1.states + nfa2.states\n",
        "                stack.append(concatenated_nfa)\n",
        "\n",
        "            elif char=='|':\n",
        "                nfa2 = stack.pop()\n",
        "                nfa1 = stack.pop()\n",
        "                new_start = State('S' + str(state_counter))\n",
        "                new_accept = State('S' +  str(state_counter +1))\n",
        "                state_counter += 2\n",
        "                edge1,edge2,edge3,edge4 = Edge(epsilon,nfa1.start),Edge(epsilon,nfa2.start),Edge(epsilon,new_accept),Edge(epsilon,new_accept)\n",
        "\n",
        "                new_start.out_edges.append(edge1)\n",
        "                nfa1.start.in_edges.append(edge1)\n",
        "\n",
        "                new_start.out_edges.append(edge2)\n",
        "                nfa2.start.in_edges.append(edge2)\n",
        "\n",
        "                nfa1.accepting.out_edges.append(edge3)\n",
        "                new_accept.in_edges.append(edge3)\n",
        "\n",
        "                nfa2.accepting.out_edges.append(edge4)\n",
        "                new_accept.in_edges.append(edge4)\n",
        "\n",
        "                ored_nfa= NFA(epsilon, new_start, new_accept)\n",
        "\n",
        "                ored_nfa.states = [new_start, new_accept] + nfa1.states + nfa2.states\n",
        "                stack.append(ored_nfa)\n",
        "\n",
        "            elif char=='*':\n",
        "                nfa = stack.pop()\n",
        "                new_start = State('S' + str(state_counter))\n",
        "                new_accept = State('S' +  str(state_counter +1))\n",
        "                state_counter += 2\n",
        "                edge1,edge2,edge3,edge4 = Edge(epsilon,nfa.start),Edge(epsilon,new_accept),Edge(epsilon,new_start),Edge(epsilon,new_accept)\n",
        "\n",
        "                new_start.out_edges.append(edge1)\n",
        "                nfa.start.in_edges.append(edge1)\n",
        "\n",
        "                nfa.accepting.out_edges.append(edge2)\n",
        "                new_accept.in_edges.append(edge2)\n",
        "\n",
        "                nfa.accepting.out_edges.append(edge3)\n",
        "                new_start.in_edges.append(edge3)\n",
        "\n",
        "                new_start.out_edges.append(edge4)\n",
        "                new_accept.in_edges.append(edge4)\n",
        "\n",
        "                zero_or_more_nfa = NFA(epsilon, new_start, new_accept)\n",
        "                zero_or_more_nfa.states = [new_start, new_accept] + nfa.states\n",
        "                stack.append(zero_or_more_nfa)\n",
        "\n",
        "            elif char=='+':\n",
        "                nfa = stack.pop()\n",
        "                new_start = State('S' + str(state_counter))\n",
        "                new_accept = State('S' +  str(state_counter +1))\n",
        "                state_counter += 2\n",
        "                edge1,edge2,edge3 = Edge(epsilon,nfa.start),Edge(epsilon,new_accept),Edge(epsilon,new_start)\n",
        "\n",
        "                new_start.out_edges.append(edge1)\n",
        "                nfa.start.in_edges.append(edge1)\n",
        "\n",
        "                nfa.accepting.out_edges.append(edge2)\n",
        "                new_accept.in_edges.append(edge2)\n",
        "\n",
        "                nfa.accepting.out_edges.append(edge3)\n",
        "                new_start.in_edges.append(edge3)\n",
        "\n",
        "                one_or_more_nfa = NFA(epsilon, new_start, new_accept)\n",
        "                one_or_more_nfa.states = [new_start, new_accept] + nfa.states\n",
        "                stack.append(one_or_more_nfa)\n",
        "\n",
        "            elif char == '?':\n",
        "                nfa = stack.pop()\n",
        "                new_start = State('S' + str(state_counter))\n",
        "                new_accept = State('S' +  str(state_counter +1))\n",
        "                state_counter += 2\n",
        "                edge1,edge2,edge3 = Edge(epsilon,nfa.start),Edge(epsilon,new_accept),Edge(epsilon,new_accept)\n",
        "\n",
        "                new_start.out_edges.append(edge1)\n",
        "                nfa.start.in_edges.append(edge1)\n",
        "\n",
        "                nfa.accepting.out_edges.append(edge2)\n",
        "                new_accept.in_edges.append(edge2)\n",
        "\n",
        "                new_start.out_edges.append(edge3)\n",
        "                new_accept.in_edges.append(edge3)\n",
        "\n",
        "                zero_or_one_nfa = NFA(epsilon, new_start, new_accept)\n",
        "                zero_or_one_nfa.states = [new_start, new_accept] + nfa.states\n",
        "                stack.append(zero_or_one_nfa)\n",
        "\n",
        "            elif char in alphanumerics:\n",
        "                start_state = State('S' + str(state_counter))\n",
        "                accept_state = State('S' +  str(state_counter +1))\n",
        "                state_counter += 2\n",
        "\n",
        "                edge = Edge(char,accept_state)\n",
        "\n",
        "                start_state.out_edges.append(edge)\n",
        "                accept_state.in_edges.append(edge)\n",
        "\n",
        "                single_char_nfa = NFA(char, start_state, accept_state)\n",
        "                single_char_nfa.states.extend([start_state,accept_state])\n",
        "\n",
        "                stack.append(single_char_nfa)\n",
        "\n",
        "        return stack.pop()\n",
        "\n",
        "    def to_json(self):\n",
        "        nfa_dict = {\"startingState\": self.start.name}\n",
        "\n",
        "        for state in self.states:\n",
        "            state_info = {\"isTerminatingState\": state == self.accepting}\n",
        "            # edge_dict = {}\n",
        "            for edge in state.out_edges:\n",
        "                # destination = None\n",
        "                # for s in self.states:\n",
        "                #     if edge in s.in_edges:\n",
        "                #         destination = s\n",
        "                #         break\n",
        "                destination = edge.dest\n",
        "\n",
        "                if edge.label in state_info:\n",
        "                  # if destination.name not in edge_dict[edge.label]:\n",
        "                    # edge_dict[edge.label].append(destination.name)\n",
        "                   state_info[edge.label] = list(state_info[edge.label]) + [destination.name]\n",
        "                else:\n",
        "                    state_info[edge.label] = [destination.name]\n",
        "\n",
        "            # for label, destinations in edge_dict.items():\n",
        "            #     state_info[label] = destinations\n",
        "\n",
        "            nfa_dict[state.name] = state_info\n",
        "\n",
        "        with open(\"NFA.json\", \"w\",encoding=\"utf-8\") as json_file:\n",
        "            json.dump(nfa_dict, json_file, indent=4, ensure_ascii=False)\n",
        "\n",
        "        return nfa_dict\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kxj6TOhvVZtv",
        "outputId": "d8ad8c34-d1bf-4111-dacc-bba5474df11c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'startingState': 'S3',\n",
              " 'S3': {'isTerminatingState': False, 'ε': ['S1']},\n",
              " 'S4': {'isTerminatingState': False, 'ε': ['S5']},\n",
              " 'S1': {'isTerminatingState': False, 'a': ['S2']},\n",
              " 'S2': {'isTerminatingState': False, 'ε': ['S4', 'S3']},\n",
              " 'S5': {'isTerminatingState': False, 'b': ['S6']},\n",
              " 'S6': {'isTerminatingState': True}}"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "postfix = shunting_yard.infix2postfix('a+b')\n",
        "# nfa = NFA.postfix2NFA(postfix='A+B*.?CD|.')\n",
        "# nfa = NFA.postfix2NFA(postfix='ab|c|d|e|fA.|B|C|')\n",
        "nfa = NFA.postfix2NFA(postfix)\n",
        "# nfa = NFA.postfix2NFA(postfix='ab|c|d|e|f0.|1|2|3|4|5|6|7|8|9|3.2.')\n",
        "nfa.to_json()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "GlnPj52gbnUs"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'graphviz'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgraphviz\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Digraph\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mvisualize_NFA\u001b[39m(nfa):\n\u001b[32m      5\u001b[39m   gra = Digraph(graph_attr={\u001b[33m'\u001b[39m\u001b[33mrankdir\u001b[39m\u001b[33m'\u001b[39m:\u001b[33m'\u001b[39m\u001b[33mLR\u001b[39m\u001b[33m'\u001b[39m})\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'graphviz'"
          ]
        }
      ],
      "source": [
        "from graphviz import Digraph\n",
        "\n",
        "def visualize_NFA(nfa):\n",
        "\n",
        "  gra = Digraph(graph_attr={'rankdir':'LR'})\n",
        "\n",
        "\n",
        "  for s in nfa.states:\n",
        "      if(s.name == nfa.start.name):\n",
        "        gra.node(\"\", _attributes={'shape' : 'none'})\n",
        "        gra.edge(\"\", s.name)\n",
        "      if(s.name == nfa.accepting.name):\n",
        "        gra.node(s.name, _attributes={'peripheries' : '2'})\n",
        "      else:\n",
        "        gra.node(s.name)\n",
        "\n",
        "  edge_set = set()\n",
        "  for state in nfa.states:\n",
        "    for edge in state.out_edges:\n",
        "\n",
        "        destination = edge.dest\n",
        "        edge_key = (state.name, destination.name, edge.label)\n",
        "        if edge_key not in edge_set:\n",
        "            edge_set.add(edge_key)\n",
        "            gra.edge(state.name, destination.name, label=edge.label)\n",
        "\n",
        "  gra.format = 'png'\n",
        "  gra.render('NFA', view = True)\n",
        "  return gra.source"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        },
        "id": "1I90DkZZnISs",
        "outputId": "ff024861-a157-4c67-d768-5caeeaaa2492"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'visualize_NFA' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[0;32m----> 2\u001b[0m \u001b[43mvisualize_NFA\u001b[49m(nfa)\n\u001b[1;32m      3\u001b[0m Image(filename\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNFA.png\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'visualize_NFA' is not defined"
          ]
        }
      ],
      "source": [
        "from IPython.display import Image\n",
        "visualize_NFA(nfa)\n",
        "Image(filename='NFA.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JdTE8Mjn_3bA"
      },
      "source": [
        "# NFA To DFA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VvKa4vSSANVk"
      },
      "outputs": [],
      "source": [
        "class DFA:\n",
        "    def __init__(self):\n",
        "        self.states = [] #supersets\n",
        "        self.start = None\n",
        "        self.accepting = []\n",
        "        self.alphabets = []\n",
        "        \n",
        "\n",
        "    def set_alphabets(self,nfa:NFA):\n",
        "        temp_alphabets = set()\n",
        "        for state in nfa.states:\n",
        "            for edge in state.out_edges:\n",
        "                if edge.label != epsilon:\n",
        "                    temp_alphabets.add(edge.label)\n",
        "\n",
        "        self.alphabets = list(temp_alphabets)\n",
        "\n",
        "    def epsilon_closure(self,states:list[State]):\n",
        "        stack = states\n",
        "        closure = set(states)\n",
        "        \n",
        "        while stack:\n",
        "            s = stack.pop()\n",
        "            for edge in s.out_edges:\n",
        "                if edge.label == epsilon and edge.dest not in closure:\n",
        "                    closure.add(edge.dest)\n",
        "                    stack.append(edge.dest)\n",
        "        return list(closure)\n",
        "\n",
        "    \n",
        "    def move(self,states:list[State], char:str):\n",
        "        destinations = []\n",
        "        for s in states:\n",
        "            for edge in s.out_edges:\n",
        "                if edge.label == char:\n",
        "                    destinations.append(edge.dest)\n",
        "        return destinations\n",
        "    \n",
        "    \n",
        "    def remove_duplicates(self,states:list[State]):\n",
        "        unique_states = []\n",
        "        seen_names = set()  \n",
        "        for state in states:\n",
        "            if state.name not in seen_names:\n",
        "                seen_names.add(state.name)  \n",
        "                unique_states.append(state)  \n",
        "        return unique_states \n",
        "    \n",
        "    def rename_states(self,transitions):\n",
        "        renamed_transitions = {}\n",
        "        states_map={}\n",
        "        i=0\n",
        "        for state in transitions:\n",
        "            if state == \"startingState\":\n",
        "                continue\n",
        "            states_map[state] = \"S\"+str(i)\n",
        "            i+=1\n",
        "        \n",
        "        for state in transitions:\n",
        "            if state == \"startingState\":\n",
        "                renamed_transitions[\"startingState\"] = states_map[transitions[\"startingState\"]]\n",
        "                continue\n",
        "            renamed_transitions[states_map[state]] = {}\n",
        "            for edge in transitions[state]:\n",
        "                if edge == \"isTerminatingState\" :\n",
        "                    renamed_transitions[states_map[state]][\"isTerminatingState\"] = transitions[state][\"isTerminatingState\"]\n",
        "                    continue\n",
        "                renamed_transitions[states_map[state]][edge] = states_map[transitions[state][edge]]\n",
        "        \n",
        "        return renamed_transitions,states_map\n",
        "    \n",
        "    \n",
        "    \n",
        "    def NFA2DFA(self,nfa:NFA):\n",
        "        self.set_alphabets(nfa)\n",
        "        start = self.epsilon_closure([nfa.start])\n",
        "        self.states.append(start)\n",
        "        self.start = start\n",
        "        \n",
        "        transitions ={}\n",
        "        start_string = \" \".join(sorted([s.name for s in self.start]))\n",
        "        transitions[\"startingState\"]= start_string\n",
        "\n",
        "        unvisited = [start]\n",
        "        while unvisited:\n",
        "            state_list = unvisited.pop()\n",
        "            for alphabet in self.alphabets:\n",
        "                destinations = self.move(state_list,alphabet)\n",
        "                if not destinations:\n",
        "                    continue\n",
        "                closure = self.epsilon_closure(destinations)\n",
        "\n",
        "            \n",
        "                for s in closure:\n",
        "                    if s == nfa.accepting:\n",
        "                        self.accepting.append(closure)\n",
        "                        break\n",
        "\n",
        "                if closure not in self.states:\n",
        "                    self.states.append(closure)\n",
        "                    unvisited.append(closure)\n",
        "                \n",
        "                from_state_string = \" \".join(sorted([s.name for s in state_list]))\n",
        "                to_state_string = \" \".join(sorted([s.name for s in closure]))\n",
        "            \n",
        "                \n",
        "                if from_state_string not in transitions:\n",
        "                    transitions[from_state_string] = {}\n",
        "\n",
        "                transitions[from_state_string][alphabet] = to_state_string\n",
        "                transitions[from_state_string][\"isTerminatingState\"] = state_list in self.accepting\n",
        "\n",
        "  \n",
        "        for state in self.accepting:\n",
        "            state_string=\" \".join(sorted([s.name for s in state]))\n",
        "            if state_string not in transitions:\n",
        "                transitions[state_string] = {}\n",
        "                transitions[state_string][\"isTerminatingState\"]=True\n",
        "                \n",
        "\n",
        "        renamed_transitions,states_map = self.rename_states(transitions)\n",
        "        for i,state in enumerate(self.states):\n",
        "            self.states[i] = State(states_map[\" \".join(sorted([s.name for s in state]))])\n",
        "        \n",
        "        for i,state in enumerate(self.accepting):\n",
        "            self.accepting[i] = State(states_map[\" \".join(sorted([s.name for s in state]))])\n",
        "            \n",
        "        self.states = self.remove_duplicates(self.states)\n",
        "        self.accepting = self.remove_duplicates(self.accepting)\n",
        "        \n",
        "        \n",
        "        \n",
        "        return transitions,renamed_transitions\n",
        "    \n",
        "            \n",
        "            \n",
        "    def to_json(self,transitions:dict,renamed_transitions:dict):\n",
        "        with open(\"DFA_transitions.json\", \"w\") as json_file:\n",
        "            json.dump(transitions, json_file, indent=4, ensure_ascii=False)\n",
        "        \n",
        "        with open(\"DFA_transitions_renamed.json\", \"w\") as json_file:\n",
        "            json.dump(renamed_transitions, json_file, indent=4, ensure_ascii=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "postfix = shunting_yard.infix2postfix('a+|b+')\n",
        "nfa = NFA.postfix2NFA(postfix)\n",
        "nfa.to_json()\n",
        "dfa = DFA()\n",
        "transitions,renamed_transitions=dfa.NFA2DFA(nfa)\n",
        "dfa.to_json(transitions,renamed_transitions)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MinimizedDFA:\n",
        "    def __init__(self, dfa: DFA, transitions: dict):\n",
        "        self.dfa = dfa\n",
        "        self.transitions = transitions\n",
        "        self.minimized_transitions = {}\n",
        "        \n",
        "    def __difference(self, states_a: list[State], states_b: list[State]):\n",
        "        names_b = {state.name for state in states_b}  \n",
        "        return [state for state in states_a if state.name not in names_b]  \n",
        "    \n",
        "    def __split(self,group: list[State],partition: list[list[State]]): \n",
        "    # If all states in the group go to the same subgroup for all inputs, don't split\n",
        "    # Otherwise, split into subgroups where states have identical transition behavior\n",
        "\n",
        "        subgroups = {}  # key: tuple of destination groups, value: list of states\n",
        "                        # ex: {(0, 1): [A, B], (1, 0): [C, D]}\n",
        "\n",
        "        for state in group:\n",
        "            destination_groups = []\n",
        "\n",
        "            for input in self.dfa.alphabets:\n",
        "                next_state = self.transitions.get(state.name, {}).get(input, None)\n",
        "                destination_groups.append(next_state)\n",
        "                for i, existing_group in enumerate(partition):\n",
        "                    if next_state in existing_group:\n",
        "                        destination_groups.append(i)\n",
        "                        break\n",
        "            \n",
        "            \n",
        "            if tuple(destination_groups) not in subgroups:\n",
        "                subgroups[tuple(destination_groups)] = []\n",
        "            subgroups[tuple(destination_groups)].append(state)\n",
        "\n",
        "        # return true if a split happens, false if no split\n",
        "        if len(subgroups) > 1:\n",
        "            return subgroups.values(),True\n",
        "        return [group],False\n",
        "\n",
        "            \n",
        "    def minimize(self):\n",
        "        # inital partition TT\n",
        "        non_accepting = self.__difference(self.dfa.states,self.dfa.accepting) # {A, B, C, D}  non accepting states\n",
        "        accepting = self.dfa.accepting # {E}  accepting states\n",
        "\n",
        "        partitions = [non_accepting, accepting] #TTnew =TT = {A, B, C, D} {E}\n",
        "        # partition is a list of lists(groups) \n",
        "        changed = True\n",
        "        while changed:\n",
        "            changed = False\n",
        "            new_partitions = []\n",
        "\n",
        "            for group in partitions:  \n",
        "                subgroups, is_split = self.__split(group, partitions)\n",
        "                if is_split:\n",
        "                    changed = True\n",
        "                new_partitions.extend(subgroups)\n",
        "\n",
        "            partitions = new_partitions\n",
        "            \n",
        "                \n",
        "        state_map = {}  \n",
        "        minimized_states = []\n",
        "        minimized_accepting = []\n",
        "        minimized_transitions = {}\n",
        "\n",
        "        # rename groups (to be one state) and check on accepting states\n",
        "        for i,group in enumerate(partitions):\n",
        "            new_state = f\"S{i}\"\n",
        "            minimized_states.append(new_state)\n",
        "            state_map[frozenset(group)] = new_state\n",
        "\n",
        "            if any(state in self.dfa.accepting for state in group):\n",
        "                minimized_accepting.append(new_state)\n",
        "\n",
        "        \n",
        "        # build transitions dict after minimization\n",
        "        for group in partitions:\n",
        "            from_state = state_map[frozenset(group)]\n",
        "            minimized_transitions[from_state] = {}\n",
        "            \n",
        "            sample_state = group[0]\n",
        "\n",
        "            for input in self.dfa.alphabets:\n",
        "                next_state = self.transitions.get(sample_state.name, {}).get(input, None)\n",
        "\n",
        "                if next_state:\n",
        "                    for group2 in partitions:\n",
        "                        for state in group2:\n",
        "                            if next_state == state.name :\n",
        "                                minimized_transitions[from_state][input] = state_map[frozenset(group2)]\n",
        "                                break\n",
        "\n",
        "\n",
        "        # add accept states\n",
        "        for state in minimized_states:\n",
        "            if state in minimized_accepting:\n",
        "                minimized_transitions[state][\"isTerminatingState\"] = True\n",
        "            else:\n",
        "                minimized_transitions[state][\"isTerminatingState\"] = False\n",
        "        \n",
        "        # add start state\n",
        "        # for group in partitions:\n",
        "        #     if self.dfa.start in group:\n",
        "        #         print(f\"start state{self.dfa.start} at group {group}\")\n",
        "        #         minimized_transitions[\"startingState\"] = state_map[frozenset(group)]\n",
        "        #         break\n",
        "\n",
        "        minimized_transitions[\"startingState\"] = self.transitions[\"startingState\"]\n",
        "                    \n",
        "        self.dfa.states = minimized_states\n",
        "        self.dfa.accepting = minimized_accepting\n",
        "        self.minimized_transitions = minimized_transitions\n",
        "\n",
        "        return minimized_transitions\n",
        "\n",
        "    def to_json(self):\n",
        "        with open(\"MinimizedDFA.json\", \"w\") as json_file:\n",
        "            json.dump(self.minimized_transitions, json_file, indent=4, ensure_ascii=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {},
      "outputs": [],
      "source": [
        "postfix = shunting_yard.infix2postfix('a+b')\n",
        "nfa = NFA.postfix2NFA(postfix)\n",
        "nfa.to_json()\n",
        "dfa = DFA()\n",
        "transitions,renamed_transitions=dfa.NFA2DFA(nfa)\n",
        "dfa.to_json(transitions,renamed_transitions)\n",
        "minimized_dfa = MinimizedDFA(dfa, renamed_transitions)\n",
        "minimized_dfa.minimize()\n",
        "minimized_dfa.to_json()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
